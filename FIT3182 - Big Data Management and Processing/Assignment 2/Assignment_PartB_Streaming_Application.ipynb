{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d78992",
   "metadata": {},
   "source": [
    "## Assignment 2 Part B Streaming Application\n",
    "\n",
    "**Name: Kang Hong Bo (Student ID:32684673)**\n",
    "\n",
    "Write a streaming application using the Apache Spark Structured Streaming API which processes data in daily batches. Each batch should contain 1 Climate report and 0 or more Hotspot reports (from Producer 2 or 3). The streaming application should process the data as follows:<br>\n",
    "- Group the Climate and Hotspots streams based on location and create the data model developed in Part A. Assume that all Hotspot reports in a batch window were generated for the current day. Use geohash precision 3 for Climate-to-Hotspot matching. You should drop any Hotspot reports that are not proximately close to the Climate report. <br>\n",
    "- If there is no Hotspot report in a batch (only Climate report is present), it implies that there was no fire for that day and we can store the Climate report into MongoDB straight away. <br>\n",
    "- Due to synchronisation issues in the communication between the satellites and the receiving station, the AQUA and TERRA satellites may unknowingly produce multiple reports for the same Hotspot event. This is characterised as Hotspot reports with similar location (geohash precision 5) and created time (<=10 minutes apart).  In such cases, you should merge these reports by averaging the ‘surface temperature’ and ‘confidence’. You are free to choose the method to merge the other fields in the reports (i.e. averaging, first/last etc.).<br>\n",
    "- If a fire was detected with an air temperature greater than 20 (°C) and a GHI greater than 180 (W/m2), then report the cause of the fire event as ‘natural’. Otherwise, report the cause of the fire event as ‘other’.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf1a84e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygeohash in /opt/conda/lib/python3.8/site-packages (1.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pygeohash # install pygeohash\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.3.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 pyspark-shell'\n",
    "# import statements \n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split, element_at, when\n",
    "import pygeohash as pgh\n",
    "import json\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "from pyspark.sql.streaming import StreamingQueryException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19c9d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 19, 'ok': 1.0}, acknowledged=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_name=\"PartB\"\n",
    "hostip = \"192.168.22.110\" ## PLEASE CHANGE THIS LINE TO YOUR HOSTIP\n",
    "client = MongoClient (hostip,27017) \n",
    "db = client.fit3182_assignment_db\n",
    "collection = db.partB\n",
    "collection.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f513cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    # import and use all of the available local processor\n",
    "    .master('local[*]')\n",
    "    .appName('Spark Application')\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "topic_stream_df = (\n",
    "    spark.readStream.format('kafka')\n",
    "    # this is set the same environment as the producers\n",
    "    .option('kafka.bootstrap.servers', f'{hostip}:9092')\n",
    "    .option('subscribe', topic_name)\n",
    "    .load()\n",
    ")\n",
    "\n",
    "output_stream_df = (\n",
    "    topic_stream_df\n",
    "    .select(                                      \n",
    "        topic_stream_df.value\n",
    "        .alias('data')\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac77b00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_stream_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eb0acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_df,batch_id):\n",
    "    raw_data = batch_df.collect()\n",
    "    streams = [json.loads(item.asDict()['data']) for item in raw_data]\n",
    "    allLoc={}\n",
    "    cData=None\n",
    "    \n",
    "\n",
    "    for stream in streams:\n",
    "        #if the current stream contains climate data then the cData will get the stream this will \n",
    "        if stream['producer'] == 'climate_streaming':\n",
    "            cData = stream\n",
    "        # get the location with precision = 3\n",
    "        location =pgh.encode(stream['latitude'],stream['longitude'],precision=3)\n",
    "        if location in allLoc:\n",
    "            allLoc[location].append(stream)\n",
    "        else:\n",
    "            allLoc[location]=[stream]\n",
    "    \n",
    "    if cData is not None:\n",
    "        cData['date']=datetime.strptime(cData['createdDate'],'%d/%m/%Y')\n",
    "        del cData['createdDate']\n",
    "        climateLocation=pgh.encode(cData['latitude'],cData['longitude'],precision=3)\n",
    "        \n",
    "        if len(allLoc[climateLocation])>1:\n",
    "            hotspots={}\n",
    "            \n",
    "            for stream in allLoc[climateLocation]:\n",
    "                producer=stream['producer']\n",
    "                \n",
    "                if producer!='climate_streaming':\n",
    "                    #get location with precesion 5\n",
    "                    location = pgh.encode(stream['latitude'],stream['longitude'],precision=5)\n",
    "                    if location in hotspots:\n",
    "                        hotspots[location].append(stream)\n",
    "                    else:\n",
    "                        hotspots[location]=[stream]\n",
    "                        \n",
    "            # Calculate fireCause according to climate data\n",
    "            fireCause = 'natural' if cData['air_temperature_celcius']> 20 and cData['GHI_w/m2']>180 else 'other'\n",
    "\n",
    "\n",
    "            hotspotsData = []    \n",
    "            #sort the hotspots by the time of the stream\n",
    "            for location in hotspots.keys():\n",
    "                hotspots_df = pd.DataFrame(hotspots[location])\n",
    "                # sort the DataFrame by the time field\n",
    "                hotspots_df = hotspots_df.sort_values(by='time')\n",
    "                # convert the sorted DataFrame back to a list of dictionaries\n",
    "                hotspots[location] = hotspots_df.to_dict('records')\n",
    "                #merge the hotspots that are within 10 minutes of each other\n",
    "                temp = hotspots[location]\n",
    "                hotspots[location] = []\n",
    "                i = 0\n",
    "                # loop through the hotspots of the location\n",
    "                while i < len(temp):\n",
    "                    j = i + 1\n",
    "                    #make the time become datetime format and check if the time is 10mins apart\n",
    "                    while j < len(temp) and (datetime.strptime(temp[j]['time'], '%H:%M:%S') - datetime.strptime(temp[i]['time'], '%H:%M:%S')).seconds <= 600:\n",
    "#                         print(\"hi\")\n",
    "                        j += 1\n",
    "                    #calculate the average surface temperature and confidence\n",
    "                    \n",
    "                    avgSurfaceTemp = sum([x['surface_temperature_celcius'] for x in temp[i:j]]) / (j - i)\n",
    "                    avgConfidence = sum([x['confidence'] for x in temp[i:j]]) / (j - i)\n",
    "                    \n",
    "                    # get the actual datetime for the hotspots\n",
    "                    specificDateTime = cData['date'].strftime(\"%Y/%m/%d \")+temp[i]['time']\n",
    "#                     print(specificDateTime)\n",
    "                    hotspots[location].append({\n",
    "                        'latitude': temp[i]['latitude'],\n",
    "                        'longitude': temp[i]['longitude'],\n",
    "                        # make the time to datetime format\n",
    "                        'time': datetime.strptime(specificDateTime,'%Y/%m/%d %H:%M:%S'),\n",
    "                        'confidence': avgConfidence,\n",
    "                        'surface_temperature_celcius': avgSurfaceTemp\n",
    "                    })\n",
    "                    i = j\n",
    "                \n",
    "\n",
    "                #create the hotspot document\n",
    "                for hotspot in hotspots[location]:\n",
    "                    hotspotsData.append({\n",
    "                        'latitude': hotspot['latitude'],\n",
    "                        'longitude': hotspot['longitude'],\n",
    "                        'time': hotspot['time'],\n",
    "                        'confidence': hotspot['confidence'],\n",
    "                        'surface_temperature_celcius': hotspot['surface_temperature_celcius']\n",
    "                    })\n",
    "            #add the single location hotspot to the climate data\n",
    "            cData['hotspots'] = hotspotsData\n",
    "            cData['fireCause'] = fireCause\n",
    "                \n",
    "    #before insert the data to the database, we need to check if the data is already in the database\n",
    "    if cData is not None:\n",
    "        if collection.find_one({'date': cData['date']}):\n",
    "            print('Data already exists in the database')\n",
    "        else:\n",
    "            pprint(cData)\n",
    "            collection.insert_one(cData)\n",
    "            print('Data inserted into the database')\n",
    "    else:\n",
    "        print('No climate data in the batch')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91cd29bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_writer = (\n",
    "    output_stream_df\n",
    "    .writeStream\n",
    "    .outputMode('append')\n",
    "    .trigger(processingTime = '10 seconds') \n",
    "    .foreachBatch(process_batch) \n",
    ")\n",
    "\n",
    "console_logger = (\n",
    "    output_stream_df\n",
    "    .writeStream\n",
    "    .outputMode('append')\n",
    "    .format('console')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cf24119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No climate data in the batch\n",
      "No climate data in the batch\n",
      "{'GHI_w/m2': 125,\n",
      " 'air_temperature_celcius': 14,\n",
      " 'date': datetime.datetime(2024, 1, 4, 0, 0),\n",
      " 'fireCause': 'other',\n",
      " 'hotspots': [{'confidence': 64.0,\n",
      "               'latitude': -37,\n",
      "               'longitude': 149,\n",
      "               'surface_temperature_celcius': 44.0,\n",
      "               'time': datetime.datetime(2024, 1, 4, 20, 39, 55)}],\n",
      " 'latitude': -37.391,\n",
      " 'longitude': 148.066,\n",
      " 'max_wind_speed': 15.9,\n",
      " 'precipitation': 0.03,\n",
      " 'precipitationFlag': 'G',\n",
      " 'producer': 'climate_streaming',\n",
      " 'relative_humidity': 44.6,\n",
      " 'windspeed_knots': 7.7}\n",
      "Data inserted into the database\n",
      "{'GHI_w/m2': 83,\n",
      " 'air_temperature_celcius': 9,\n",
      " 'date': datetime.datetime(2024, 1, 5, 0, 0),\n",
      " 'fireCause': 'other',\n",
      " 'hotspots': [{'confidence': 68.0,\n",
      "               'latitude': -37,\n",
      "               'longitude': 149,\n",
      "               'surface_temperature_celcius': 43.0,\n",
      "               'time': datetime.datetime(2024, 1, 5, 6, 45, 35)},\n",
      "              {'confidence': 90.0,\n",
      "               'latitude': -37,\n",
      "               'longitude': 148,\n",
      "               'surface_temperature_celcius': 66.0,\n",
      "               'time': datetime.datetime(2024, 1, 5, 17, 49, 20)},\n",
      "              {'confidence': 89.0,\n",
      "               'latitude': -37,\n",
      "               'longitude': 148,\n",
      "               'surface_temperature_celcius': 61.0,\n",
      "               'time': datetime.datetime(2024, 1, 5, 22, 3, 29)}],\n",
      " 'latitude': -37.45,\n",
      " 'longitude': 148.097,\n",
      " 'max_wind_speed': 9.9,\n",
      " 'precipitation': 0.0,\n",
      " 'precipitationFlag': 'G',\n",
      " 'producer': 'climate_streaming',\n",
      " 'relative_humidity': 41.0,\n",
      " 'windspeed_knots': 8.2}\n",
      "Data inserted into the database\n",
      "{'GHI_w/m2': 154,\n",
      " 'air_temperature_celcius': 20,\n",
      " 'date': datetime.datetime(2024, 1, 6, 0, 0),\n",
      " 'latitude': -38.16,\n",
      " 'longitude': 143.803,\n",
      " 'max_wind_speed': 15.0,\n",
      " 'precipitation': 0.0,\n",
      " 'precipitationFlag': 'I',\n",
      " 'producer': 'climate_streaming',\n",
      " 'relative_humidity': 62.2,\n",
      " 'windspeed_knots': 7.1}\n",
      "Data inserted into the database\n",
      "{'GHI_w/m2': 152,\n",
      " 'air_temperature_celcius': 17,\n",
      " 'date': datetime.datetime(2024, 1, 7, 0, 0),\n",
      " 'latitude': -36.3782,\n",
      " 'longitude': 143.7313,\n",
      " 'max_wind_speed': 27.0,\n",
      " 'precipitation': 0.24,\n",
      " 'precipitationFlag': 'G',\n",
      " 'producer': 'climate_streaming',\n",
      " 'relative_humidity': 44.9,\n",
      " 'windspeed_knots': 16.1}\n",
      "Data inserted into the database\n",
      "{'GHI_w/m2': 81,\n",
      " 'air_temperature_celcius': 9,\n",
      " 'date': datetime.datetime(2024, 1, 8, 0, 0),\n",
      " 'fireCause': 'other',\n",
      " 'hotspots': [{'confidence': 89.0,\n",
      "               'latitude': -36,\n",
      "               'longitude': 143,\n",
      "               'surface_temperature_celcius': 65.0,\n",
      "               'time': datetime.datetime(2024, 1, 8, 20, 57, 47)}],\n",
      " 'latitude': -36.5243,\n",
      " 'longitude': 142.0839,\n",
      " 'max_wind_speed': 9.9,\n",
      " 'precipitation': 0.0,\n",
      " 'precipitationFlag': 'G',\n",
      " 'producer': 'climate_streaming',\n",
      " 'relative_humidity': 43.9,\n",
      " 'windspeed_knots': 5.7}\n",
      "Data inserted into the database\n",
      "{'GHI_w/m2': 90,\n",
      " 'air_temperature_celcius': 10,\n",
      " 'date': datetime.datetime(2024, 1, 9, 0, 0),\n",
      " 'fireCause': 'other',\n",
      " 'hotspots': [{'confidence': 83.0,\n",
      "               'latitude': -37,\n",
      "               'longitude': 142,\n",
      "               'surface_temperature_celcius': 56.0,\n",
      "               'time': datetime.datetime(2024, 1, 9, 14, 34, 51)}],\n",
      " 'latitude': -37.013,\n",
      " 'longitude': 141.5355,\n",
      " 'max_wind_speed': 12.0,\n",
      " 'precipitation': 0.39,\n",
      " 'precipitationFlag': 'G',\n",
      " 'producer': 'climate_streaming',\n",
      " 'relative_humidity': 44.1,\n",
      " 'windspeed_knots': 7.3}\n",
      "Data inserted into the database\n",
      "{'GHI_w/m2': 90,\n",
      " 'air_temperature_celcius': 10,\n",
      " 'date': datetime.datetime(2024, 1, 10, 0, 0),\n",
      " 'fireCause': 'other',\n",
      " 'hotspots': [{'confidence': 86.0,\n",
      "               'latitude': -37,\n",
      "               'longitude': 142,\n",
      "               'surface_temperature_celcius': 60.0,\n",
      "               'time': datetime.datetime(2024, 1, 10, 1, 0, 11)},\n",
      "              {'confidence': 82.0,\n",
      "               'latitude': -37,\n",
      "               'longitude': 142,\n",
      "               'surface_temperature_celcius': 56.0,\n",
      "               'time': datetime.datetime(2024, 1, 10, 15, 1, 11)}],\n",
      " 'latitude': -37.013,\n",
      " 'longitude': 141.5355,\n",
      " 'max_wind_speed': 12.0,\n",
      " 'precipitation': 0.39,\n",
      " 'precipitationFlag': 'G',\n",
      " 'producer': 'climate_streaming',\n",
      " 'relative_humidity': 44.1,\n",
      " 'windspeed_knots': 7.3}\n",
      "Data inserted into the database\n",
      "{'GHI_w/m2': 107,\n",
      " 'air_temperature_celcius': 12,\n",
      " 'date': datetime.datetime(2024, 1, 11, 0, 0),\n",
      " 'fireCause': 'other',\n",
      " 'hotspots': [{'confidence': 62.0,\n",
      "               'latitude': -37,\n",
      "               'longitude': 148,\n",
      "               'surface_temperature_celcius': 47.0,\n",
      "               'time': datetime.datetime(2024, 1, 11, 4, 21, 30)}],\n",
      " 'latitude': -37.379,\n",
      " 'longitude': 148.132,\n",
      " 'max_wind_speed': 11.1,\n",
      " 'precipitation': 0.0,\n",
      " 'precipitationFlag': 'G',\n",
      " 'producer': 'climate_streaming',\n",
      " 'relative_humidity': 44.9,\n",
      " 'windspeed_knots': 7.9}\n",
      "Data inserted into the database\n",
      "{'GHI_w/m2': 203,\n",
      " 'air_temperature_celcius': 24,\n",
      " 'date': datetime.datetime(2024, 1, 12, 0, 0),\n",
      " 'fireCause': 'natural',\n",
      " 'hotspots': [{'confidence': 100.0,\n",
      "               'latitude': -37,\n",
      "               'longitude': 143,\n",
      "               'surface_temperature_celcius': 93.0,\n",
      "               'time': datetime.datetime(2024, 1, 12, 13, 46, 27)}],\n",
      " 'latitude': -36.5794,\n",
      " 'longitude': 142.5959,\n",
      " 'max_wind_speed': 15.0,\n",
      " 'precipitation': 0.0,\n",
      " 'precipitationFlag': 'I',\n",
      " 'producer': 'climate_streaming',\n",
      " 'relative_humidity': 51.8,\n",
      " 'windspeed_knots': 7.9}\n",
      "Data inserted into the database\n",
      "{'GHI_w/m2': 223,\n",
      " 'air_temperature_celcius': 28,\n",
      " 'date': datetime.datetime(2024, 1, 13, 0, 0),\n",
      " 'latitude': -37.864,\n",
      " 'longitude': 144.174,\n",
      " 'max_wind_speed': 18.1,\n",
      " 'precipitation': 0.04,\n",
      " 'precipitationFlag': 'G',\n",
      " 'producer': 'climate_streaming',\n",
      " 'relative_humidity': 58.4,\n",
      " 'windspeed_knots': 11.9}\n",
      "Data inserted into the database\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/opt/conda/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted. Stopped query\n"
     ]
    }
   ],
   "source": [
    "writer = db_writer\n",
    "try:\n",
    "    query = writer.start()\n",
    "    query.awaitTermination()\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted. Stopped query')\n",
    "except StreamingQueryException as exc:\n",
    "    print(exc)\n",
    "finally:\n",
    "    query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7799bf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2411538b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
